{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from config import *\n",
    "import glob\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# import seaborn as sns\n",
    "# import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii in range(1):\n",
    "    times = 0\n",
    "    start = 0\n",
    "    end = 0\n",
    "    print('Start with %d'%ii+'\\n')\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    np.random.seed(1)\n",
    "    tf.random.set_seed(346)\n",
    "\n",
    "    # -- define the network\n",
    "    layer1 = keras.layers.Conv2D(16, kernel_size=(5, 5), padding=\"valid\", activation=\"relu\", input_shape=(51, 153, 1))\n",
    "    layer2 = keras.layers.MaxPooling2D((2, 2), strides=2)\n",
    "    layer3 = keras.layers.Conv2D(32, kernel_size=(5, 5), padding=\"valid\", activation=\"relu\", input_shape=(51, 153, 1))\n",
    "    layer4 = keras.layers.MaxPooling2D((2, 2), strides=2)\n",
    "    layer5 = keras.layers.Flatten()\n",
    "    #layer6 = keras.layers.Dropout(0.4)\n",
    "    layer7 = keras.layers.Dense(32, activation=\"relu\")\n",
    "    layer8 = keras.layers.Dense(2, activation=\"softmax\")\n",
    "    layers = [layer1, layer2, layer3, layer4, layer5, layer7,layer8]\n",
    "\n",
    "    # -- instantiate the convolutional neural network\n",
    "    model = keras.Sequential(layers)\n",
    "\n",
    "    opt = keras.optimizers.SGD(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    \n",
    "    train = np.load('../data/data_split/train%d'%ii+'.npy') \n",
    "    test = np.load('../data/data_split/test%d'%ii+'.npy')\n",
    "#     train = np.load('../data/data_split/train_small.npy') \n",
    "#     test = np.load('../data/data_split/test_small.npy')\n",
    "\n",
    "#     np.random.seed(7)\n",
    "#     random_index_train = np.random.choice(len(train_full), size=10200, replace=False)\n",
    "#     np.random.seed(3)\n",
    "#     random_index_test = np.random.choice(len(test_full), size=400, replace=False)\n",
    "\n",
    "#     train = train_full[random_index_train,:,:]\n",
    "#     test = test_full[random_index_test,:,:]\n",
    "\n",
    "#     trainID = trainID_full[random_index_train]\n",
    "#     testID = testID_full[random_index_test]\n",
    "\n",
    "    train_targ = np.load('../data/data_split/train_targ_%d'%ii+'.npy')\n",
    "    test_targ = np.load('../data/data_split/test_targ_%d'%ii+'.npy') \n",
    "\n",
    "#     train_targ = np.load('../data/data_split/train_targ_small.npy')\n",
    "#     test_targ = np.load('../data/data_split/test_targ_small.npy')\n",
    "\n",
    "#     train_targ = train_targ_full[random_index_train]\n",
    "#     test_targ = test_targ_full[random_index_test]\n",
    "\n",
    "    print(train.shape, test.shape)\n",
    "    print('unique test: {}'.format(np.unique(test_targ, return_counts=True)))\n",
    "    print('unique train: {}'.format(np.unique(train_targ, return_counts=True)))\n",
    "    \n",
    "    # -- feautres need to have an extra axis on the end (for mini-batching)\n",
    "    feat_tr2 = train.reshape(len(train), 51, 153, 1)\n",
    "    feat_te2 = test.reshape(len(test), 51, 153, 1)\n",
    "\n",
    "    # -- fit the model\n",
    "    history = model.fit(feat_tr2, train_targ, validation_split=0.20, epochs=40, batch_size=20)\n",
    "\n",
    "    # -- print the accuracy\n",
    "    loss_tr, acc_tr = model.evaluate(feat_tr2, train_targ, verbose=False)\n",
    "    loss_te, acc_te = model.evaluate(feat_te2, test_targ, verbose=False)\n",
    "\n",
    "    print(\"Training accuracy : {0:.4f}\".format(acc_tr))\n",
    "    print(\"Testing accuracy  : {0:.4f}\".format(acc_te))\n",
    "\n",
    "    end = time.time()\n",
    "    times  = (end - start)\n",
    "    print(times)\n",
    "\n",
    "\n",
    "    # file1 = open(\"../outputs/stamps%d\"%ii+\"/results.txt\",\"a\")\n",
    "#     file1 = open(\"results.txt\",\"a\")\n",
    "#     file1.write(\"\\n{},{}\\n\".format(train.shape, test.shape))\n",
    "#     file1.write('unique test_%d'%ii+': {} \\n'.format(np.unique(test_targ, return_counts=True)))\n",
    "#     file1.write('unique train_%d'%ii+': {} \\n'.format(np.unique(train_targ, return_counts=True)))\n",
    "#     file1.write(\"Training accuracy GPUCPU for stamps%d\"%ii+\": {0:.4f} \\n\".format(acc_tr))\n",
    "#     file1.write(\"Testing accuracy GPUCPU for stamps%d\"%ii+\": {0:.4f} \\n\".format(acc_te))\n",
    "#     file1.write(\"Time in seconds GPUCPU for stamps%d\"%ii+\": {0:.4f} \\n\".format(times))\n",
    "#     file1.close()\n",
    "    \n",
    "    print('Done {}'.format(ii))\n",
    "\n",
    "\n",
    "\n",
    "    # -- plot the loss function\n",
    "#     fig, ax = plt.subplots(2,1,figsize=(8, 8))\n",
    "#     ax[0].plot(history.history[\"loss\"])\n",
    "#     ax[0].plot(history.history[\"val_loss\"])\n",
    "#     ax[0].legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "#     ax[0].set_xlabel(\"epoch\", fontsize=15)\n",
    "#     ax[0].set_ylabel(\"loss\", fontsize=15)\n",
    "\n",
    "#     ax[1].plot(history.history[\"accuracy\"])\n",
    "#     ax[1].plot(history.history[\"val_accuracy\"])\n",
    "#     ax[1].legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "#     ax[1].set_xlabel(\"epoch\", fontsize=15)\n",
    "#     ax[1].set_ylabel(\"acc\", fontsize=15)\n",
    "    #plt.savefig(\"../outputs/stamps%d\"%ii+\"/lossacc_correctGPUGPU.pdf\",bbox_inches=\"tight\")\n",
    "\n",
    "# print('Done {}'.format(ii))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix for test data\n",
    "# y_pred = model.predict(feat_te2)\n",
    "# con_mat = tf.math.confusion_matrix(labels=test_targ, predictions=np.argmax(y_pred,axis=1)).numpy()\n",
    "# con_mat.flatten()\n",
    "# con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    " \n",
    "# con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "#                      index = [0,1], \n",
    "#                      columns = [0,1])\n",
    "# con_mat_norm.flatten()\n",
    "# labels = [f\"{v1}\\n{v2*100}%\" for v1, v2 in\n",
    "#           zip(con_mat.flatten(),con_mat_norm.flatten())]\n",
    "\n",
    "# labels = np.asarray(labels).reshape(2,2)\n",
    "# categories = [\"0: Real\", \"1: Bogus\"]\n",
    "\n",
    "# figure = plt.figure(figsize=(4, 5))\n",
    "# sns.heatmap(con_mat, annot=labels,cbar=False,fmt='',xticklabels=categories,yticklabels=categories,cmap='Pastel2_r')#plt.cm.Blues)\n",
    "# plt.tight_layout()\n",
    "# plt.ylabel('True label')\n",
    "# plt.xlabel('Predicted label')\n",
    "# #plt.savefig(\"confusionmatrix_small_GPUGPUTAC_7030.pdf\",bbox_inches=\"tight\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 47, 149, 16)       416       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 23, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 19, 70, 32)        12832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 9, 35, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10080)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                322592    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 335,906\n",
      "Trainable params: 335,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tff-TAC",
   "language": "python",
   "name": "tff-tac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
